---
layout: post
title: (Writing) 일어나야해! 넌 조선의 자존심이야! (2/2)
date: 2024-07-27 01:48 +0900
description: 로아 회고글
category: [프로젝트, reflection]
tags: [Krafton Jungle, LOA, Nest, LLM]
---

전편에서는 클라이언트와 서비스 방향이 중점이였다면, 이번 편은 조금 더 백엔드 중심적인 이야기이자 기술적인 내용을 담고 있다.

## 서버 이슈
---
### Web Mediapipe
전편에서 말한 결과로 사용자 상태 분석은 백엔드에서 이뤄지게 됐는데, 사용자 상태 분석에 사용되는 프레임워크인 mediapipe는 Web과 모바일, Python을 지원했다. 백엔드가 node 환경이니 손쉽게 Web용 mediapipe를 사용하면 된다. 자연스럽게 npm install 후 기본 코드를 실행시켰지만 document 관련 코드가 없는 오류가 발생했다. Web용 mediapipe는 브라우저용 javascript다. 따라서 node.js에서는 document 관련된 구현체가 제공되지 않으니 당연히 실행되지 않는 것이였다.

node 환경에서 mediapipe를 실행시키려면 실제 mediapipe의 c++ 라이브러리를 래핑해서 사용할 수 있다. 또는 Python을 지원해주니 파이썬 프로세스를 생성하여 요청을 처리할 수도 있다. c++ 라이브러리를 래핑해서 사용하는 것보다는 파이썬 프로세스를 이용하는 게 훨씬 간단하고 관리가 쉬워보였다.

### 파이썬 프로세스
상태 분석을 위해 익스텐션에서 초당 한장씩 사용자 웹캠으로부터 이미지를 캡처하여 백엔드로 전송한다. 전송받은 이미지를 nest 서버에서 파이썬 프로세스를 생성하여 분석하고 눈감음 정도나 사람 존재 유무와 같은 분석된 결과를 응답한다. 익스텐션에서는 이 결과값들을 기반으로 사용자 상태를 확정 짓고 알맞는 알림을 제공하게 된다.

혼자 테스트할 때 정상적인 것을 확인하고, 배포 후 다른 팀원과 같이 테스트를 진행했다. 이 과정에서 30분 정도가 지나니 서버로 요청이 가지 않는 문제가 발생했다. 확인해보니 서버가 죽어있던 것이였다. 이럴수가!

Postman으로 API를 호출해서 확인해보니 응답 시간이 1초대가 넘어갔다. 1초마다 사용자 이미지를 보내는데 처리하는 시간이 1초를 넘기니 계속 작업이 쌓이게 되는 것이였다. AWS에서 제공하는 Cloud watch를 사용해서 CPU 사용량을 모니터링 해봤는데, 실제로도 한 명이 사용할 때 몇분 지나지 않아서 곧장 20%에 도달했고 계속 상승했다.

이 수치가 심각하게 느껴졌던 게 mediapipe는 클라이언트용 모델이기에 굉장히 가볍고 빨랐으며 CPU 부하가 적은 것을 로컬에서 확인했기 때문이다. 아무리 t3.micro 인스턴스라도 이것은 아니라고 생각했다.

프로세스를 매번 생성하는 비용이 컸다. 매 요청마다 파이썬 프로세스를 생성하고 mediapipe 모델을 로드하고 처리하고 결과값이 반환됨과 동시에 프로세스가 종료되는 것이 반복되는 것이였다. 그리하여 파이썬 프로세스를 계속 띄워놓을 방법이 필요했다. 이 띄워진 프로세스에 nest 서버로 요청받은 이미지를 전달하고, 이미지를 처리한 결과값을 다시 전달 받아서 응답해주면 됐다.

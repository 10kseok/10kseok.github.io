---
layout: post
title: (Writing) 일어나야해! 넌 조선의 자존심이야! (2/2)
date: 2024-07-27 01:48 +0900
description: 로아 회고글
category: [프로젝트, reflection]
tags: [Krafton Jungle, LOA, Nest, LLM, 크래프톤 정글 회고]
---

전편에서는 클라이언트와 서비스 방향이 중점이였다면, 이번 편은 조금 더 백엔드 중심적인 이야기이자 기술적인 내용을 담고 있다.

## 서버 이슈
---
### Web Mediapipe
전편에서 말한 결과로 사용자 상태 분석은 백엔드에서 이뤄지게 됐는데, 사용자 상태 분석에 사용되는 프레임워크인 mediapipe는 Web과 모바일, Python을 지원했다. 백엔드가 node 환경이니 손쉽게 Web용 mediapipe를 사용하면 된다. 자연스럽게 패키지 설치 후 기본 코드를 실행시켰지만 document 관련 코드가 없는 오류가 발생했다. Web용 mediapipe는 브라우저용 javascript다. 따라서 node.js에서는 document 관련된 구현체가 제공되지 않아 실행되지 않았다.

node 환경에서 mediapipe를 실행시키려면 실제 mediapipe의 c++ 라이브러리를 래핑해서 사용할 수 있다. 또는 Python을 지원해주니 파이썬 프로세스를 생성하여 요청을 처리할 수도 있다. c++ 라이브러리를 래핑해서 사용하는 것보다는 파이썬 프로세스를 이용하는 게 훨씬 간단하고 관리가 쉬워보였다.

### 파이썬 프로세스
상태 분석을 위해 익스텐션에서 사용자 웹캠으로부터 초당 한장씩 이미지를 캡처하여 백엔드로 전송한다. nest 서버가 전송받은 이미지를 파이썬 프로세스에 전달하여 눈감음 정도나 사람 존재 유무와 같은 분석된 결과를 응답한다. 익스텐션에서는 이 결과값들을 기반으로 사용자 상태를 확정 짓고 알맞는 알림을 제공하게 된다.

*이럴수가! 서버가 죽었다*. 혼자 테스트할 때 정상적인 것을 확인하고, 배포 후 다른 팀원과 같이 테스트를 진행했다. 이 과정에서 30분 정도가 지나니 서버로 요청이 가지 않는 문제가 발생했다. 확인해보니 서버가 죽어있던 것이였다.

Postman으로 API를 호출해서 확인해보니 응답 시간이 1초대가 넘어갔다. 1초마다 사용자 이미지를 보내는데 처리하는 시간이 1초를 넘기니 계속 작업이 쌓이게 되는 것이였다. AWS에서 제공하는 Cloud watch를 사용해서 CPU 사용량을 모니터링 해봤는데, 실제로 한 명이 사용할 때 몇분 지나지 않아서 곧장 20%에 도달했고 계속 상승했다.

이 수치가 심각하게 느껴졌던 게 mediapipe는 클라이언트용 모델이다. 그렇다보니 굉장히 가볍고 로컬(브라우저)에서 동작할 때도 빨랐으며 CPU 부하가 적었다. 아무리 t3.micro 인스턴스라도 이것은 아니라고 생각했다.

매번 프로세스를 생성하는 게 문제다. 이 과정에는 프로그램 파일을 읽는 파일 I/O 작업부터해서 mediapipe 모델을 로드해서 이미지 분석, 프로세스 종료 후 메모리 회수 등 많은 작업들이 중복되게 된다. 이 불필요한 중복 과정을 제거하기 위해 파이썬 프로세스를 계속 띄워놓을 방법이 필요했다. 이 띄워진 프로세스에 nest 서버로 요청받은 이미지를 전달하고, 이미지를 처리한 결과값을 다시 전달 받아서 응답해주면 될 것이다.

### 이미지 처리 서버 구축
**파이썬 프로세스는 어떻게든 종료되지 않게 한다치고, 이미지는 어떻게 전달해야할까**
1. 이미지를 파일로 저장해두고 파이썬 프로세스에서 이미지 저장 경로를 전달한다.
2. 이미지를 적재하고 전달해줄 메세지 브로커를 도입한다.
3. 운영체제에서 제공하는 공유 메모리에 이미지를 저장시켜 전달한다.
4. 이미지만을 처리하는 파이썬 서버를 구축하여 이미지를 전달하지 않고 직접 받아 처리한다.  

이미지는 사용자 상태 분석을 위한 일회성 데이터이기에 파일로 저장하기에는 비용이 너무 컸다. 또한 이미지만 전달하면 되는데 메세지 브로커를 도입하는 것도 부담스러웠다. 공유 메모리를 사용하자니 메모리에 추가적인 read/write 연산이 생기고 여러 요청이 들어오면 관리하기가 곤란했다.

파이썬 프로세스를 계속 띄워두고 이미지 분석 요청이 들어올 때만 처리해줄 방법이 필요했는데, 그러한 애플리케이션을 우리는 이미 클라이언트-서버 모델에서 **서버**라고 하지 않았던가! 앞선 말한 문제들을 모두 해결하고 가장 간단한 해결방법은 4번이였다. 이미지 분석 결과만 얻을 수 있으면 됐기에 꼭 nest 서버내에서 처리할 필요도 없다.

>백엔드를 담당하고 있으면서도, 서버를 마지막으로 떠올렸다는게 참 아이러니하다. 이제서야 서버의 의미를 제대로 깨달은 듯하다.

이미지 처리에 대한 응답속도가 10배(1200~1500ms -> 90~100ms)나 빨라졌다. 이미지 처리 서버도 비동기 프레임워크인 FastAPI로 선택했고 직접 이미지를 처리하면서 이미지 전달과 프로세스 기반 처리 오버헤드를 없앨 수 있었다. 드디어 서버가 버티기 시작했다. 나와 다른 분들이 같이 이용해도 CPU 사용률이 1~2%로 안정적인 사용이 가능해졌다. 

응답속도가 빠를 수록 이미지 처리 정체가 없어지기에 많은 요청을 처리할 수 있다. 응답속도를 추가로 2배(90~100ms -> 40~60ms) 빠르게 만들었다. 이미지 처리 서버를 구축하면서 이미지 처리 관련 코드를 들여다보니 매 처리마다 모델을 불러오고 분석을 하는 것이였다. 

사실상 모든 이미지 처리에 대해 동일한 분석을 하기 때문에, 모델 로드는 처음 한번만 진행하면 될 것으로 생각했다. 따라서 이미지 처리 객체를 전역으로 두고 이미지 처리 함수를 처음 호출하는 시점만 모델을 로드해주고 이후 호출에는 객체를 재사용했다.

*빨라진 건 좋지만, 그러면.. 이제 서버가 사용자 몇 명을 버틸 수 있지...?*

## 성능 측정
---
서버의 한계를 측정해볼 필요가 있다. 부하 테스트 도구를 찾아보니 여러 개가 존재했다. 자세한 내용보단 간략한 정보와 간단한 사용법을 제공하는 locust를 선택했다. locust는 파이썬으로 내가 원하는 동작을 정의하여 사용할 수 있었고 결과를 직관적인 UI로 제공해줬다.

실제 웹캠에서 이미지를 20장 정도 찍어서 1초에 한장씩 전송해봤다. 제일 처음 50명 정도로 진행했는데 RPS(Requests Per Second)는 약 40 rps, 평균 응답시간은 270ms가 나왔다.

50명이 초당 하나씩 요청하면 rps가 50이 나와야 하는 게 아닌가 싶었다. 이 부분은 멘토님께 물었는데 요청을 보내고 응답 받는데에서 네트워크 지연이 있다고 하셨다. 그러고보니 네트워크를 타니깐 이러한 지연은 당연한 것이였다. 또한, 이미지를 보내다보니 이미지 파일을 읽고, 전송할 때 쓰기 작업이 일어나면서 추가로 지연이 생긴 것 같다.

동시 요청수를 늘리면서 이상함을 감지했다. 동시 사용자가 50명일 때 40 rps가 나왔는데 100명으로 늘렸을 때 겨우 50 rps가 나왔다. 150명으로 늘렸을 때도 rps가 비슷했다.

CPU 사용률이 확인했다. 동시 사용자를 50명으로 두고했을 때 CPU 사용률이 20~30%에 맴돌았고, 100명으로 증가시킨 뒤에는 CPU 사용률이 40%에 도달했다. 그런데 150명으로 늘렸을 때에도 CPU 사용률이 40%대가 유지됐다.

CPU를 온전히 사용하지 못하고 있는 것으로 판단했다. ec2 인스턴스가 t3.mirco로 가상 쓰레드가 2개였는데 마치 한 개만 사용하는 느낌이였다. 단순하게 생각했을 때, CPU 사용을 최대로 만들기 위해서 하나의 서버를 더 만들면 되지 않을까 싶었다.

우선, 이미지 처리 서버내에서 하나의 프로세스 더 만들어서 처리했다. 이전에 응답속도가 1초대가 넘어갈 때와 성능이 똑같았다. 이미지 처리 서버를 포트를 다르게 하여 하나 더 띄웠다. 그런데 이렇게 되면 클라이언트에서의 호스트명(도메인:포트) 변경이 필요했다. 누구는 요청을 A 서버로 하고 누구는 B 서버로 해야되는데 그냥 하드코딩으로 하기에는 너무 확장성이 떨어지고 유연하지 못했다.

nginx을 이용한 로드 밸런서를 도입했다. 클라이언트에서는 기존의 엔드포인트는 유지하면서 호스트(ec2 인스턴스)에서 nginx를 통해 두 개의 이미지 처리 서버로 요청을 분산시켰다. 다시 부하 테스트를 진행하는데 최저 10에서 최대 80까지 rps가 굉장히 들쑥날쑥했다.

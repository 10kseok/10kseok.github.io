---
layout: post
title: (Writing) 일어나야해! 넌 조선의 자존심이야! (2/2)
date: 2024-07-27 01:48 +0900
description: 로아 회고글
category: [프로젝트, reflection]
tags: [Krafton Jungle, LOA, Nest, LLM, 크래프톤 정글 회고]
---

전편에서는 클라이언트와 서비스 방향이 중점이였다면, 이번 편은 조금 더 백엔드 중심적인 이야기이자 기술적인 내용을 담고 있다.

## 서버 이슈
---
### Web Mediapipe
전편에서 말한 결과로 사용자 상태 분석은 백엔드에서 이뤄지게 됐는데, 사용자 상태 분석에 사용되는 프레임워크인 mediapipe는 Web과 모바일, Python을 지원했다. 백엔드가 node 환경이니 손쉽게 Web용 mediapipe를 사용하면 된다. 자연스럽게 패키지 설치 후 기본 코드를 실행시켰지만 document 관련 코드가 없는 오류가 발생했다. Web용 mediapipe는 브라우저용 javascript다. 따라서 node.js에서는 document 관련된 구현체가 제공되지 않아 실행되지 않았다.

node 환경에서 mediapipe를 실행시키려면 실제 mediapipe의 c++ 라이브러리를 래핑해서 사용할 수 있다. 또는 Python을 지원해주니 파이썬 프로세스를 생성하여 요청을 처리할 수도 있다. c++ 라이브러리를 래핑해서 사용하는 것보다는 파이썬 프로세스를 이용하는 게 훨씬 간단하고 관리가 쉬워보였다.

### 파이썬 프로세스
상태 분석을 위해 익스텐션에서 사용자 웹캠으로부터 초당 한장씩 이미지를 캡처하여 백엔드로 전송한다. nest 서버가 전송받은 이미지를 파이썬 프로세스에 전달하여 눈감음 정도나 사람 존재 유무와 같은 분석된 결과를 응답한다. 익스텐션에서는 이 결과값들을 기반으로 사용자 상태를 확정 짓고 알맞는 알림을 제공하게 된다.

*이럴수가! 서버가 죽었다*. 혼자 테스트할 때 정상적인 것을 확인하고, 배포 후 다른 팀원과 같이 테스트를 진행했다. 이 과정에서 30분 정도가 지나니 서버로 요청이 가지 않는 문제가 발생했다. 확인해보니 서버가 죽어있던 것이였다.

Postman으로 API를 호출해서 확인해보니 응답 시간이 1초대가 넘어갔다. 1초마다 사용자 이미지를 보내는데 처리하는 시간이 1초를 넘기니 계속 작업이 쌓이게 되는 것이였다. AWS에서 제공하는 Cloud watch를 사용해서 CPU 사용량을 모니터링 해봤는데, 실제로 한 명이 사용할 때 몇분 지나지 않아서 곧장 20%에 도달했고 계속 상승했다.

이 수치가 심각하게 느껴졌던 게 mediapipe는 클라이언트용 모델이다. 그렇다보니 굉장히 가볍고 로컬(브라우저)에서 동작할 때도 빨랐으며 CPU 부하가 적었다. 아무리 t3.micro 인스턴스라도 이것은 아니라고 생각했다.

매번 프로세스를 생성하는 게 문제다. 이 과정에는 프로그램 파일을 읽는 파일 I/O 작업부터해서 mediapipe 모델을 로드해서 이미지 분석, 프로세스 종료 후 메모리 회수 등 많은 작업들이 중복되게 된다. 이 불필요한 중복 과정을 제거하기 위해 파이썬 프로세스를 계속 띄워놓을 방법이 필요했다. 이 띄워진 프로세스에 nest 서버로 요청받은 이미지를 전달하고, 이미지를 처리한 결과값을 다시 전달 받아서 응답해주면 될 것이다.

### 이미지 처리 서버 구축
**파이썬 프로세스는 어떻게든 종료되지 않게 한다치고, 이미지는 어떻게 전달해야할까**
1. 이미지를 파일로 저장해두고 파이썬 프로세스에서 이미지 저장 경로를 전달한다.
2. 이미지를 적재하고 전달해줄 메세지 브로커를 도입한다.
3. 운영체제에서 제공하는 공유 메모리에 이미지를 저장시켜 전달한다.
4. 이미지만을 처리하는 파이썬 서버를 구축하여 이미지를 전달하지 않고 직접 받아 처리한다.  

이미지는 사용자 상태 분석을 위한 일회성 데이터이기에 파일로 저장하기에는 비용이 너무 컸다. 또한 이미지만 전달하면 되는데 메세지 브로커를 도입하는 것도 부담스러웠다. 공유 메모리를 사용하자니 메모리에 추가적인 read/write 연산이 생기고 여러 요청이 들어오면 관리하기가 곤란했다.

파이썬 프로세스를 계속 띄워두고 이미지 분석 요청이 들어올 때만 처리해줄 방법이 필요했는데, 그러한 애플리케이션을 우리는 이미 클라이언트-서버 모델에서 **서버**라고 하지 않았던가! 앞선 말한 문제들을 모두 해결하고 가장 간단한 해결방법은 4번이였다. 이미지 분석 결과만 얻을 수 있으면 됐기에 꼭 nest 서버내에서 처리할 필요도 없다.

>백엔드를 담당하고 있으면서도, 서버를 마지막으로 떠올렸다는게 참 아이러니하다. 이제서야 서버의 의미를 제대로 깨달은 듯하다.

이미지 처리에 대한 응답속도가 10배(1200~1500ms -> 90~100ms)나 빨라졌다. 이미지 처리 서버도 비동기 프레임워크인 FastAPI로 선택했고 직접 이미지를 처리하면서 이미지 전달과 프로세스 기반 처리 오버헤드를 없앨 수 있었다. 드디어 서버가 버티기 시작했다. 나와 다른 분들이 같이 이용해도 CPU 사용률이 1~2%로 안정적인 사용이 가능해졌다. 

응답속도가 빠를 수록 이미지 처리 정체가 없어지기에 많은 요청을 처리할 수 있다. 응답속도를 추가로 2배(90~100ms -> 40~60ms) 빠르게 만들었다. 이미지 처리 서버를 구축하면서 이미지 처리 관련 코드를 들여다보니 매 처리마다 모델을 불러오고 분석을 하는 것이였다. 

사실상 모든 이미지 처리에 대해 동일한 분석을 하기 때문에, 모델 로드는 처음 한번만 진행하면 될 것으로 생각했다. 따라서 이미지 처리 객체를 전역으로 두고 이미지 처리 함수를 처음 호출하는 시점만 모델을 로드해주고 이후 호출에는 객체를 재사용했다.

*빨라진 건 좋지만, 그러면.. 이제 서버가 사용자 몇 명을 버틸 수 있지...?*

## 성능 측정
---
### 부하 테스트
서버의 한계를 측정해볼 필요가 있다. 부하 테스트 도구를 찾아보니 여러 개가 존재했다. 자세한 내용보단 간략한 정보와 간단한 사용법을 제공하는 locust를 선택했다. locust는 파이썬으로 내가 원하는 동작을 정의하여 사용할 수 있었고 결과를 직관적인 UI로 제공해줬다.

실제 웹캠에서 이미지를 20장 정도 찍어서 1초에 한장씩 전송해봤다. 제일 처음 50명 정도로 진행했는데 RPS(Requests Per Second)는 약 40 rps, 평균 응답시간은 270ms가 나왔다.

50명이 초당 하나씩 요청하면 rps가 50이 나와야 하는 게 아닌가 싶었다. 이 부분은 멘토님께 물었는데 요청을 보내고 응답 받는데에서 네트워크 지연이 있다고 하셨다. 그러고보니 네트워크를 타니깐 이러한 지연은 당연한 것이였다. 또한, 이미지를 보내다보니 이미지 파일을 읽고, 전송할 때 쓰기 작업이 일어나면서 추가로 지연이 생긴 것 같다.

동시 요청수를 늘리면서 이상함을 감지했다. 동시 사용자가 50명일 때 40 rps가 나왔는데 100명으로 늘렸을 때 겨우 50 rps가 나왔다. 150명으로 늘렸을 때도 rps가 비슷했다.

CPU 사용률이 확인했다. 동시 사용자를 50명으로 두고했을 때 CPU 사용률이 20~30%에 맴돌았고, 100명으로 증가시킨 뒤에는 CPU 사용률이 40%에 도달했다. 그런데 150명으로 늘렸을 때에도 CPU 사용률이 40%대가 유지됐다.

CPU를 온전히 사용하지 못하고 있는 것으로 판단했다. ec2 인스턴스가 t3.mirco로 코어(vCpu)가 2개였는데 마치 한 개만 사용하는 느낌이였다. 단순하게 생각했을 때, CPU 사용을 최대로 만들기 위해서 하나의 서버를 더 만들면 되지 않을까 싶었다.

### 멀티 프로세싱
코어를 최대한 활용하기위해 두 가지 방법을 시도했다.
1. 도커 컨테이너를 사용해서 애플리케이션을 두 개 생성하고, nginx로 로드 밸런싱을 해준다.
2. gunicorn을 통해 프로세스를 여러개 생성하고 uvicorn으로 처리한다.

두 가지 방법 모두 클라이언트에서 요청 호스트 변경없이 이뤄질 수 있었다. nginx을 이용한 방법을 먼저 시도했는데, 아래 이미지와 같이 최저 10에서 최대 80까지 rps가 굉장히 들쑥날쑥했다. 이 원인을 정확하게는 모르겠으나, 로드 밸런싱이 제대로 되지 않았거나 도커 네트워크 설정 문제였던 것 같다.
![nginx+docker](https://github.com/user-attachments/assets/3634b375-01bb-4c55-8b16-53b2e4d21f8d){: width="50%"}

gunicorn과 uvicorn을 같이 사용하면 코어를 최대한 활용할 수 있다. 하지만 실제로 시도해보니 이전에 프로세스를 생성하고 제거할 때에 성능과 같았다. 실패다. 다른 멀티 프로세싱 방법이 필요하다.
>gunicorn과 uvicorn은 미들웨어로써 웹서버와 파이썬 애플리케이션 중간에 위치하여 파이썬 애플리케이션을 실행한 결과를 웹 서버로 전달한다. gunicorn은 WSGI(Web Server Gateway Interface)이며 쓰레드 기반으로 요청을 처리하고, uvicorn은 ASGI(Asynchronous Server Gateway Interface)이며 이벤트 루프로 요청을 처리한다.

uvicorn의 worker라는 파라미터가 존재했다. 서버를 기동할 때 이 파라미터를 전달해주면 uvicorn에 쓰일 프로세스의 갯수를 정할 수가 있었다. 우리의 인스턴스는 코어가 2개 였으니 worker를 그에 맞게 설정해주고 다시 기동시켰더니 아래와 같은 결과 나왔다.  
![uvicorn+2worker](https://github.com/user-attachments/assets/9b6138af-d929-4171-9d98-c51bc9dc4794){: width="50%"}

cpu 사용량은 80~90%로 드디어 코어를 최대한 활용하고 있다. 사용자를 150명으로도 늘려봤으나 rps는 그다지 늘지 않았고 응답 시간만 늘어나는 것으로 보아, 한 인스턴스당 100명까지는 안정적으로 서비스가 가능할 것으로 판단했다.

>갑자기 사용자가 늘어나는 상황에 스케일 아웃이 가능하게끔 리더님과 같이 오토 스케일링 그룹에 넣어봤다. 인스턴스가 생성되고 환경이 구축되는 시간도 있으니, 바로 적용되려면 스케일 아웃되는 시점을 잘 잡아야겠다는 생각이 들었다.
